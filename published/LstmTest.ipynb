{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LstmTest.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EPPPg_9X9yrN","colab_type":"text"},"source":["Let's try out a very basic LSTM. There are plenty of examples around that use LSTM for things like stock market prediction etc, but I had trouble to find a very simple example where you can see what's happening. We give it a sample input with a random 0/1 sequence and want a 2-lag: the LSTM should memorize the last two values and output the next to last.\n","\n","As [this explains](https://www.damienpontifex.com/2017/12/06/understanding-tensorflows-rnn-inputs-outputs-and-shapes/), the LSTM input has three dimensions: the batch size, the sequence size and the number of features. Compare also [Recurrent Neural Networks (RNNs) with Keras](https://ekababisong.org/gcp-ml-seminar/keras/#recurrent-neural-networks-rnns-with-keras). I assume you cannot use 2 dimensional (sequence size + features) since that'd be computationally inefficient."]},{"cell_type":"code","metadata":{"id":"rGh6hBl2XEpY","colab_type":"code","outputId":"38b3d71b-73d4-4570-90d3-30c18273464f","executionInfo":{"status":"ok","timestamp":1562510567962,"user_tz":-120,"elapsed":2170,"user":{"displayName":"Hans-Peter Störr","photoUrl":"https://lh5.googleusercontent.com/-UsuI5t4TsSg/AAAAAAAAAAI/AAAAAAAAAUU/oy9GqeEoAZE/s64/photo.jpg","userId":"04327305437195241378"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#@title Imports and utilities {display-mode: \"form\"}\n","\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.python.keras import backend as K\n","from tensorflow.python.ops import array_ops\n","from tensorflow.python.ops import math_ops\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import sklearn as sk\n","import numpy as np\n","import functools\n","import itertools\n","import time\n","import os\n","import datetime\n","\n","print([tf.__version__, pd.__version__, sns.__version__ ,plt.matplotlib.__version__,np.__version__])\n","\n","\n","# Display training progress by printing a single dot for each completed epoch\n","class PrintDot(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs):\n","    if epoch % 100 == 0: print('')\n","    print('.', end='')\n","\n","early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, min_delta=0.001, verbose=1)\n","terminate_nan = keras.callbacks.TerminateOnNaN()\n","\n","def plot_history(history):\n","    hist = pd.DataFrame(history.history)\n","    hist['epoch'] = history.epoch\n","\n","    plt.figure()\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Val Loss')\n","    plt.semilogy(hist['epoch'], hist['loss'], label='Train Error')\n","    # plt.plot(hist['epoch'], hist['val_loss'], label='Val Error')\n","    # plt.ylim([0,5])\n","    plt.legend()\n","    \n","def meanAndVariance(y_true, y_pred):\n","  y_pred = tf.convert_to_tensor(y_pred)\n","  y_true = math_ops.cast(y_true, y_pred.dtype)\n","  means = y_pred[..., 0::2]\n","  variances = y_pred[..., 1::2]\n","  res = K.square(means - y_true) + K.square(variances - K.square(means - y_true))\n","  return K.mean(res, axis=-1)\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["['1.14.0', '0.24.2', '0.9.0', '3.0.3', '1.16.4']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YEzyamwX3k4u","colab_type":"text"},"source":["We generate a batch of random sequences and roll the sequence by one to get the expected result, as visible in the printed examples."]},{"cell_type":"code","metadata":{"id":"4EKdO1oXfre5","colab_type":"code","outputId":"a7f3f295-9b1a-4df1-e5d6-edbeda3a9ab8","executionInfo":{"status":"ok","timestamp":1562510567969,"user_tz":-120,"elapsed":2158,"user":{"displayName":"Hans-Peter Störr","photoUrl":"https://lh5.googleusercontent.com/-UsuI5t4TsSg/AAAAAAAAAAI/AAAAAAAAAUU/oy9GqeEoAZE/s64/photo.jpg","userId":"04327305437195241378"}},"colab":{"base_uri":"https://localhost:8080/","height":302}},"source":["def shiftedSequenceInput(seqlength,numsequences):\n","  sequences = [np.random.choice([0,1],seqlength)*2.0-1 for _ in range(numsequences)]\n","  # sequences = [np.random.randn(seqlength)*2.0-1 for _ in range(numsequences)]\n","  shifted = [np.roll(x,2) for x in sequences]\n","  #print(sequences)\n","  #print(shifted)\n","  return (np.asarray(sequences).reshape([numsequences,seqlength,1]), np.asarray(shifted).reshape([numsequences,seqlength,1]))\n","\n","seqlength=128\n","data=shiftedSequenceInput(seqlength,512)\n","print(data[0].shape)\n","print(data[0][3].T)\n","print(data[1][3].T)\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["(512, 128, 1)\n","[[ 1. -1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1.  1.  1. -1.  1. -1.  1.\n","   1.  1. -1. -1. -1.  1. -1.  1. -1. -1.  1.  1. -1.  1. -1.  1.  1. -1.\n","  -1. -1. -1.  1.  1. -1.  1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1.\n","  -1. -1. -1.  1. -1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.\n","   1. -1.  1.  1.  1. -1.  1.  1. -1. -1. -1. -1. -1.  1.  1. -1. -1.  1.\n","   1.  1.  1. -1. -1.  1. -1. -1. -1. -1.  1.  1.  1. -1.  1. -1.  1. -1.\n","   1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1.\n","  -1.  1.]]\n","[[-1.  1.  1. -1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1.  1.  1. -1.  1.\n","  -1.  1.  1.  1. -1. -1. -1.  1. -1.  1. -1. -1.  1.  1. -1.  1. -1.  1.\n","   1. -1. -1. -1. -1.  1.  1. -1.  1.  1. -1. -1. -1.  1.  1. -1. -1. -1.\n","  -1.  1. -1. -1. -1.  1. -1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.\n","   1. -1.  1. -1.  1.  1.  1. -1.  1.  1. -1. -1. -1. -1. -1.  1.  1. -1.\n","  -1.  1.  1.  1.  1. -1. -1.  1. -1. -1. -1. -1.  1.  1.  1. -1.  1. -1.\n","   1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1.\n","   1.  1.]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7FoPciiH4ieo","colab_type":"text"},"source":["A cross correlation plot between input and expected output on example no. 3 from the batch nicely shows a maximum at 1 (our shift)."]},{"cell_type":"code","metadata":{"id":"GQ9b_HzKm60w","colab_type":"code","outputId":"5f73f499-89dd-4970-b62a-a32a89bbde8f","executionInfo":{"status":"ok","timestamp":1562510568223,"user_tz":-120,"elapsed":2384,"user":{"displayName":"Hans-Peter Störr","photoUrl":"https://lh5.googleusercontent.com/-UsuI5t4TsSg/AAAAAAAAAAI/AAAAAAAAAUU/oy9GqeEoAZE/s64/photo.jpg","userId":"04327305437195241378"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"source":["plt.xcorr(data[1][3].T[0], data[0][3].T[0],maxlags=10)\n","plt.show()"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOMGEAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"gbGsE8-n47gi","colab_type":"text"},"source":["For the LSTM we need return_sequences=True since we have an expected output for every step - you could also train with just the expected final output."]},{"cell_type":"code","metadata":{"id":"O9veWH_Ogv0L","colab_type":"code","outputId":"5f696023-48f2-49fc-8d7f-62c44e2813ea","executionInfo":{"status":"ok","timestamp":1562335089335,"user_tz":-120,"elapsed":256279,"user":{"displayName":"Hans-Peter Störr","photoUrl":"https://lh5.googleusercontent.com/-UsuI5t4TsSg/AAAAAAAAAAI/AAAAAAAAAUU/oy9GqeEoAZE/s64/photo.jpg","userId":"04327305437195241378"}},"colab":{"base_uri":"https://localhost:8080/","height":188}},"source":["model = tf.keras.Sequential()\n","l=tf.keras.layers.LSTM(5,\n","                       # dropout=0.2, recurrent_dropout=0.2,\n","                               return_sequences=True)\n","model.add(l)\n","model.add(tf.keras.layers.Dense(1))\n","\n","model.compile(loss=tf.losses.mean_squared_error, optimizer='adam', metrics=[tf.losses.mean_squared_error])\n","\n","%time history=model.fit(data[0], data[1] , steps_per_epoch=10, epochs=300, verbose=0, callbacks=[PrintDot()])\n","\n","print(history.history['loss'][-1])\n","plot_history(history)\n","# print(datetime.datetime.now())\n","model.summary()\n","print(history.history)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0707 14:42:47.727120 140207605532544 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0707 14:42:48.162747 140207605532544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["\n","................................."],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HEBj6NC037Xy","colab_type":"text"},"source":["The loss doesn't get any lower because there is a fundamental problem with the loss function. The first two outputs on each sequence are always off, since there is no history the network can draw from. But the loss function counts these, too. So we have to wrap the loss function to skip the first values:"]},{"cell_type":"code","metadata":{"id":"ywCCUPPHzv51","colab_type":"code","colab":{}},"source":["def skipForLoss(loss, skip):\n","  def skipping(y_true, y_pred): \n","    return loss(y_true[:,skip:,::], y_pred[:,skip:,::])\n","  return skipping\n","\n","skippedmae = skipForLoss(tf.losses.mean_squared_error, 3)\n","\n","model.compile(loss=skippedmae, optimizer='adam', metrics=[skippedmae])\n","\n","%time history=model.fit(data[0], data[1] , steps_per_epoch=10, epochs=200, verbose=0, callbacks=[PrintDot()])\n","\n","print(history.history['loss'][-1])\n","plot_history(history)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zl0gnflvzoGc","colab_type":"code","colab":{}},"source":["i=data[0][[3],:,:]\n","o=data[1][[3],:,:]\n","p=model.predict(i)\n","print(i.flatten()[-18:])\n","print(o.flatten()[-18:])\n","print(p.flatten()[-18:])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4XHzDtwB5MWz","colab_type":"text"},"source":["We find that nice spike also at shift 2 in the cross correlation between the input and the prediction."]},{"cell_type":"code","metadata":{"id":"wHLQB4oAoDzu","colab_type":"code","colab":{}},"source":["plt.xcorr(p.flatten(), i.flatten(),maxlags=10)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VH3BvMx--uEG","colab_type":"text"},"source":["Out of curiosity: let's see whether the model generalizes to inputs -0.5, 0.5. Obviously not particularily good - we'd need to use examples for this."]},{"cell_type":"code","metadata":{"id":"NwENaAnp6qsr","colab_type":"code","colab":{}},"source":["i=data[0][[3],:,:]*0.5\n","o=data[1][[3],:,:]*0.5\n","p=model.predict(i)\n","print(i.flatten()[-18:])\n","print(o.flatten()[-18:])\n","print(p.flatten()[-18:])\n","plt.xcorr(p.flatten(), i.flatten(),maxlags=10)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U_rY-8a7ksMa","colab_type":"code","colab":{}},"source":["# predicting using a different sequence length\n","# does not work :-( \n","# we get ValueError: Error when checking input: expected lstm_7_input to have shape (128, 1) but got array with shape (64, 1)\n","data2=shiftedSequenceInput(64,512)\n","i=data2[0][[3],:,:]\n","o=data2[1][[3],:,:]\n","p=model.predict(i)\n","print(i.flatten()[-18:])\n","print(o.flatten()[-18:])\n","print(p.flatten()[-18:])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Ei4SPBMwRBF","colab_type":"text"},"source":["## Using a generator\n","\n","I don't like the separation between the data and the labels into different data structures - that makes shuffling difficult. And probably it's better to have many batches if you have lots of data, but that 3 dimensional input format doesn't allow several batches. So we try to use [Model.fit_generator](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit_generator) with a python generator spewing out batches. Each batch is (data,labels) where both data and labels have three dimensions: data[sequencenumber, timestep, inputnumber] (or outputnumber, that is).\n","\n","Don't ask me why the generator is called 11 times more than steps_per_epoch * epochs.\n"]},{"cell_type":"code","metadata":{"id":"cy5Bw2IayBcw","colab_type":"code","colab":{}},"source":["numberOfGeneratorCalls = 0\n","def dataGenerator():\n","  while True:\n","    global numberOfGeneratorCalls\n","    numberOfGeneratorCalls = numberOfGeneratorCalls + 1\n","    \n","    sequence = np.random.choice([0,1],seqlength)*2.0-1\n","    expected = np.roll(sequence,2)\n","    # here, each batch consists of one sequence. That's probably not advisable in practice for efficiency reasons\n","    yield (sequence.reshape([1,-1,1]), expected.reshape([1,-1,1]))\n","\n","history = model.fit_generator(dataGenerator(), steps_per_epoch=5, epochs=5, verbose=0)\n","print(history.history['loss'][-1])\n","\n","numberOfGeneratorCalls"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f66N0mnv2LfY","colab_type":"text"},"source":["## Prediction variants"]},{"cell_type":"code","metadata":{"id":"GwsWFoRdpHcK","colab_type":"code","colab":{}},"source":["m1 = tf.keras.Sequential()\n","l1=tf.keras.layers.LSTM(2, \n","                        # input_shape=(3,2), # seems not neccesary, but doesn't hurt either\n","                        return_sequences=True)\n","m1.add(l1)\n","m1.add(tf.keras.layers.Dense(5))\n","\n","m1.compile(loss=tf.losses.mean_squared_error, optimizer='adam', metrics=[tf.losses.mean_squared_error])\n","\n","# %time history=m1.fit(data[0], data[1] , steps_per_epoch=10, epochs=300, verbose=0, callbacks=[PrintDot()])\n","\n","d = np.random.randn(4,3,2)  # [sequencenumber, timestep, inputnumber]\n","l = np.random.randn(4,3,5) # [sequencenumber, timestep, outputnumber]\n","# m1.fit(d,l)\n","m1.fit_generator( (x for x in [(d,l)]), steps_per_epoch=1, epochs=1 )\n","print(m1.predict(d).shape)\n","print(m1.predict_generator( (x for x in [d,d,d]), steps = 1000 ).shape) # nonsense."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KwrREmnj2OcV","colab_type":"code","colab":{}},"source":["m1.predict(np.random.randn(4,7,2)).shape \n","# different sequence length -> OK, except if we give an input_shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NCc2h8Zj67Vo","colab_type":"code","colab":{}},"source":["m1.predict(np.random.randn(7,3,2)).shape # different number of batches -> OK"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4x8khDPh5YWG","colab_type":"code","colab":{}},"source":["# does not work: different number of inputs\n","try:\n","  m1.predict(np.random.randn(4,3,7)).shape\n","except Exception as e:\n","  print('OK: got ', type(e), e)\n","else:\n","  assert False, \"This should throw an IllegalArgumentError\""],"execution_count":0,"outputs":[]}]}